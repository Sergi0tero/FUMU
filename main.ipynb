{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0b7d035",
   "metadata": {},
   "source": [
    "# Entrono #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb09cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03f7dc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Pub/Sub Broker\n",
    "# ----------------------------\n",
    "class PubSubBroker:\n",
    "    def __init__(self):\n",
    "        self.subscribers = []\n",
    "\n",
    "    def subscribe(self, callback):\n",
    "        self.subscribers.append(callback)\n",
    "\n",
    "    def publish(self, data):\n",
    "        for callback in self.subscribers:\n",
    "            callback(data)\n",
    "\n",
    "# ----------------------------\n",
    "# Whiteboard (memoria compartida)\n",
    "# ----------------------------\n",
    "class Whiteboard:\n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "\n",
    "    def write(self, key, value):\n",
    "        self.data[key] = value\n",
    "\n",
    "    def read(self):\n",
    "        while len(self.data) < 2:\n",
    "            print(\"Esperando datos en la pizarra... \", self.data)\n",
    "            time.sleep(5)\n",
    "        return dict(self.data)\n",
    "\n",
    "    def clear(self):\n",
    "        self.data = {}\n",
    "\n",
    "# ----------------------------\n",
    "# DataFetcher (Insertar agente de recolección de datos)\n",
    "# ----------------------------\n",
    "class DataFetcher:\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "        self.index = 0\n",
    "\n",
    "    def has_next(self):\n",
    "        return self.index < len(self.df)\n",
    "    \n",
    "    def get_next_ticker(self):\n",
    "        if self.index < len(self.df):\n",
    "            return self.df.iloc[self.index]['Ticker']\n",
    "        return None\n",
    "\n",
    "    def fetch_data(self):\n",
    "        current = self.df.loc[self.index]\n",
    "        self.index += 1\n",
    "        return current\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fb2ddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class traditionalAgent:\n",
    "    def __init__(self, broker, whiteboard, data_fetcher):\n",
    "        self.broker = broker\n",
    "        self.whiteboard = whiteboard\n",
    "        self.data_fetcher = data_fetcher\n",
    "        self.df = None\n",
    "        self.broker.subscribe(self.group_traditional)\n",
    "\n",
    "    def set_dataframe(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def group_traditional(self, data):\n",
    "        idx = self.data_fetcher.index\n",
    "        if idx < 2 or self.df is None:\n",
    "            self.whiteboard.write('trad_pred', data['Close'])\n",
    "            return\n",
    "\n",
    "        # Filtrar histórico por ticker actual\n",
    "        df_hist = self.df.iloc[:idx].copy()\n",
    "        df_hist = df_hist[df_hist['Ticker'] == data['Ticker']].reset_index(drop=True)\n",
    "\n",
    "        if len(df_hist) < 10:\n",
    "            self.whiteboard.write('trad_pred', data['Close'])\n",
    "            return\n",
    "\n",
    "        # Columnas predictoras\n",
    "        features = ['Open', 'High', 'Low', 'Volume', 'RSI', 'SMA_20', 'MACD']\n",
    "\n",
    "        # Objetivo: Close futuro (t+1)\n",
    "        df_hist['Close_Future'] = df_hist['Close'].shift(-1)\n",
    "        df_hist = df_hist.fillna(method='ffill')\n",
    "\n",
    "        try:\n",
    "            X = df_hist[features]\n",
    "            y = df_hist['Close_Future']\n",
    "            current_features = np.array([data[f] for f in features]).reshape(1, -1)\n",
    "\n",
    "            # pred1: Regresión lineal multivariable\n",
    "            model1 = LinearRegression()\n",
    "            model1.fit(X, y)\n",
    "            pred1 = model1.predict(current_features)[0]\n",
    "\n",
    "            # pred2: Gradient Boosting multivariable\n",
    "            model2 = GradientBoostingRegressor()\n",
    "            model2.fit(X, y)\n",
    "            pred2 = model2.predict(current_features)[0]\n",
    "\n",
    "        except Exception:\n",
    "            pred1 = pred2 = data['Close']\n",
    "\n",
    "        avg = (pred1 + pred2) / 2\n",
    "        self.whiteboard.write('trad_pred', avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90d1469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgenteIA:\n",
    "    def __init__(self, broker, whiteboard, data_fetcher):\n",
    "        self.broker = broker\n",
    "        self.whiteboard = whiteboard\n",
    "        #self.broker.subscribe(self.group_ai)\n",
    "        self.data_fetcher = data_fetcher\n",
    "\n",
    "        # Inicializa embeddings y base de datos vectorial\n",
    "        self.embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "        self.db = None  # Se cargará después con documentos reales\n",
    "\n",
    "    def cargar_documentos(self, ruta):\n",
    "        documentos = []\n",
    "        for archivo in os.listdir(ruta):\n",
    "            if archivo.endswith(\".txt\"):\n",
    "                documentos.extend(TextLoader(os.path.join(ruta, archivo)).load())\n",
    "            elif archivo.endswith(\".pdf\"):\n",
    "                documentos.extend(PyPDFLoader(os.path.join(ruta, archivo)).load())\n",
    "        return documentos\n",
    "\n",
    "    def dividir_chunks(self, documentos):\n",
    "        splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "        return splitter.split_documents(documentos)\n",
    "\n",
    "    def crear_o_cargar_chromadb(self, chunks, persist_directory=\"db_finanzas\"):\n",
    "        if not os.path.exists(persist_directory):\n",
    "            self.db = Chroma.from_documents(chunks, self.embedding_function, persist_directory=persist_directory)\n",
    "            self.db.persist()\n",
    "        else:\n",
    "            self.db = Chroma(persist_directory=persist_directory, embedding_function=self.embedding_function)\n",
    "\n",
    "    def consulta_lmstudio(self, prompt):\n",
    "        url = \"http://localhost:1234/v1/chat/completions\"\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "        data = {\n",
    "            \"messages\": [{\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Eres un asistente que responde SOLO con JSON, nunca expliques, nunca incluyas texto adicional.\\n\" + prompt\n",
    "            }],\n",
    "            \"temperature\": 0.4,\n",
    "            \"max_tokens\": 1048\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    def consulta_rag(self, pregunta):\n",
    "        if self.db is None:\n",
    "            raise Exception(\"La base de datos vectorial no ha sido cargada.\")\n",
    "        similares = self.db.similarity_search(pregunta, k=3)\n",
    "        contexto = \"\\n\\n\".join([doc.page_content for doc in similares])\n",
    "\n",
    "        prompt = f\"\"\"Con base en el siguiente contexto, responde la pregunta solo en formato JSON válido con claves 'fecha' y 'valor':\n",
    "\n",
    "        Contexto:\n",
    "        {contexto}\n",
    "\n",
    "        Pregunta: {pregunta}\n",
    "        \"\"\"\n",
    "        res = self.consulta_lmstudio(prompt)\n",
    "        return res\n",
    "\n",
    "    def group_ai(self, data):\n",
    "        stock_symbol = data.get('Ticker')\n",
    "        current_date = pd.to_datetime(data['Datetime'])\n",
    "        df_stock = self.data_fetcher.df\n",
    "        df_filtrado = df_stock[(df_stock['Ticker'] == stock_symbol) & (pd.to_datetime(df_stock['Datetime']) < current_date)]\n",
    "        if df_filtrado.empty or current_date < pd.to_datetime(\"2025-07-13\"):\n",
    "            self.whiteboard.write('ai_pred', data['Close'])  # fallback\n",
    "            return\n",
    "        df_historico = df_filtrado.sort_values(by='Datetime')\n",
    "        texto_contexto_historico = df_historico.to_string(index=False)\n",
    "        if self.data_fetcher.index > 1:\n",
    "            last_close = self.data_fetcher.df.loc[self.data_fetcher.index - 2]['Close']\n",
    "        else:\n",
    "            last_close = data['Close']\n",
    "            \n",
    "        pregunta = f\"\"\"Dado el siguiente historial de precios del activo {stock_symbol}, ¿cuál sería una predicción razonable del valor de cierre para el día y la hora {data['Datetime']}?\n",
    "        \n",
    "        Historial:\n",
    "        {texto_contexto_historico}\n",
    "        \n",
    "        Responde en formato JSON, un solo elemento con la siguiente estructura: {{ \"fecha\": \"AAAA-MM-DD hh:mm \", \"valor\": <número> }}\"\"\"\n",
    "        try:\n",
    "            respuesta = self.consulta_rag(pregunta)\n",
    "            resultado = eval(respuesta)\n",
    "            print(resultado)\n",
    "            print(\"----------------------------\")\n",
    "            avg = resultado['valor']\n",
    "        except Exception as e:\n",
    "            print(\"Error en predicción:\", e)\n",
    "            avg = last_close  # fallback\n",
    "        self.whiteboard.read\n",
    "        self.whiteboard.write('ai_pred', avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33c94a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# MarketEnvironment\n",
    "# ----------------------------\n",
    "class MarketEnvironment:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.data_fetcher = DataFetcher(df)\n",
    "        self.broker = PubSubBroker()\n",
    "        self.whiteboard = Whiteboard()\n",
    "        self.histories = {}  # Diccionario para almacenar cada empresa\n",
    "\n",
    "        # Agentes de predicción\n",
    "        self.agentsTraditional = traditionalAgent(self.broker, self.whiteboard, self.data_fetcher)\n",
    "        self.agentsIA = AgenteIA(self.broker, self.whiteboard, self.data_fetcher)\n",
    "        self.agentsTraditional.set_dataframe(df)\n",
    "\n",
    "        documentos = self.agentsIA.cargar_documentos(\"documentos\")\n",
    "        chunks = self.agentsIA.dividir_chunks(documentos)\n",
    "        self.agentsIA.crear_o_cargar_chromadb(chunks)\n",
    "        \n",
    "        # Suscribir los grupos de agentes al broker\n",
    "        self.broker.subscribe(self.agentsTraditional.group_traditional)\n",
    "        self.broker.subscribe(self.agentsIA.group_ai)\n",
    "\n",
    "    def run(self):\n",
    "        tickers = self.df['Ticker'].unique().tolist()\n",
    "\n",
    "        for ticker in tickers:\n",
    "            print(f\"Iniciando simulación para {ticker}...\")\n",
    "\n",
    "            df_ticker = self.df[self.df['Ticker'] == ticker].reset_index(drop=True)\n",
    "            self.data_fetcher = DataFetcher(df_ticker)\n",
    "            self.agentsTraditional.set_dataframe(df_ticker)\n",
    "\n",
    "            self.histories[ticker] = pd.DataFrame(columns=['Datetime', 'Real_Close', 'Trad_Prediction', 'AI_Prediction'])\n",
    "\n",
    "            # Primer paso: hacer la primera predicción (usando t)\n",
    "            if not self.data_fetcher.has_next():\n",
    "                continue\n",
    "            current_data = self.data_fetcher.fetch_data()\n",
    "            self.whiteboard.clear()\n",
    "            self.broker.publish(current_data)\n",
    "            last_prediction = self.whiteboard.read()  # ← esto reemplaza a last_data\n",
    "\n",
    "            while self.data_fetcher.has_next():\n",
    "                current_data = self.data_fetcher.fetch_data()\n",
    "\n",
    "                # Guardar la predicción previa (hecha en t) contra el valor real de t+1\n",
    "                self.histories[ticker].loc[len(self.histories[ticker])] = [\n",
    "                    current_data['Datetime'],\n",
    "                    current_data['Close'],\n",
    "                    last_prediction.get('trad_pred', current_data['Close']),\n",
    "                    last_prediction.get('ai_pred', current_data['Close'])\n",
    "                ]\n",
    "\n",
    "                #print(\n",
    "                #    f\"[{current_data['Datetime']}] {ticker} | \"\n",
    "                #    f\"Real: {current_data['Close']:.2f} | \"\n",
    "                #    f\"Tradicional: {last_prediction.get('trad_pred', current_data['Close']):.2f} | \"\n",
    "                #    f\"IA: {last_prediction.get('ai_pred', current_data['Close']):.2f}\"\n",
    "                #)\n",
    "\n",
    "                # Hacer predicción para t+2 usando datos de t+1\n",
    "                self.whiteboard.clear()\n",
    "                self.broker.publish(current_data)\n",
    "                last_prediction = self.whiteboard.read()\n",
    "\n",
    "            self.plot_graph(ticker)\n",
    "            #self.histories[ticker].to_excel(f\"simulacion_{ticker}.xlsx\", index=False)\n",
    "            print(f\"✔ Terminó {ticker}\")\n",
    "\n",
    "\n",
    "    def plot_graph(self, ticker):\n",
    "        history = self.histories[ticker]\n",
    "\n",
    "        # Ignorar el primer punto\n",
    "        history = history.iloc[1:]\n",
    "\n",
    "        plt.figure(figsize=(12,5))\n",
    "        plt.plot(history['Datetime'], history['Real_Close'], label='Precio Real', marker='o')\n",
    "        plt.plot(history['Datetime'], history['Trad_Prediction'], label='Predicción Tradicional', linestyle='--', marker='x')\n",
    "        plt.plot(history['Datetime'], history['AI_Prediction'], label='Predicción IA', linestyle='-.', marker='s')\n",
    "        plt.legend()\n",
    "        plt.title(f'Simulación Multiagente - {ticker}')\n",
    "        plt.xlabel('Tiempo')\n",
    "        plt.ylabel('Precio de Cierre')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6e64e8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PyPDFLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# Cargar datos\u001b[39;00m\n\u001b[32m      6\u001b[39m     df = pd.read_excel(\u001b[33m\"\u001b[39m\u001b[33mhistorico_top10_indicadores_completos.xlsx\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     env = \u001b[43mMarketEnvironment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     env.run()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mMarketEnvironment.__init__\u001b[39m\u001b[34m(self, df)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mself\u001b[39m.agentsIA = AgenteIA(\u001b[38;5;28mself\u001b[39m.broker, \u001b[38;5;28mself\u001b[39m.whiteboard, \u001b[38;5;28mself\u001b[39m.data_fetcher)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mself\u001b[39m.agentsTraditional.set_dataframe(df)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m documentos = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magentsIA\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcargar_documentos\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocumentos\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m chunks = \u001b[38;5;28mself\u001b[39m.agentsIA.dividir_chunks(documentos)\n\u001b[32m     19\u001b[39m \u001b[38;5;28mself\u001b[39m.agentsIA.crear_o_cargar_chromadb(chunks)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mAgenteIA.cargar_documentos\u001b[39m\u001b[34m(self, ruta)\u001b[39m\n\u001b[32m     16\u001b[39m         documentos.extend(TextLoader(os.path.join(ruta, archivo)).load())\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m archivo.endswith(\u001b[33m\"\u001b[39m\u001b[33m.pdf\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m         documentos.extend(\u001b[43mPyPDFLoader\u001b[49m(os.path.join(ruta, archivo)).load())\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m documentos\n",
      "\u001b[31mNameError\u001b[39m: name 'PyPDFLoader' is not defined"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Main\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Cargar datos\n",
    "    df = pd.read_excel(\"historico_top10_indicadores_completos.xlsx\")\n",
    "    env = MarketEnvironment(df)\n",
    "    env.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ba83fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
